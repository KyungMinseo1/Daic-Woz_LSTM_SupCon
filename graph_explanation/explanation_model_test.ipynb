{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf21b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path().cwd().resolve().parent\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e177c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import os, argparse, path_config, shutil\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_networkx, k_hop_subgraph\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from graph.train_val import train_gat, validation_gat, FocalLoss\n",
    "\n",
    "from graph._multimodal_model_bilstm.GAT_explanation import GATJKClassifier as BiLSTMV2GAT\n",
    "from graph.multimodal_topic_bilstm_proxy.dataset_explanation import make_graph as TopicProxyBiLSTM_make_graph\n",
    "\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52210612",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.remove()\n",
    "logger.add(\n",
    "  sys.stdout,\n",
    "  colorize=True,\n",
    "  format=\"<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>\",\n",
    ")\n",
    "\n",
    "V2_MODEL = {\n",
    "  'multimodal_topic_bilstm_proxy':BiLSTMV2GAT\n",
    "}\n",
    "\n",
    "MAKE_GRAPH = {\n",
    "  'multimodal_topic_bilstm_proxy':TopicProxyBiLSTM_make_graph\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c258d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_from_db(db_path):\n",
    "  con = sqlite3.connect(db_path)\n",
    "  cursor = con.cursor()\n",
    "  cursor.execute('''\n",
    "    SELECT param_name, param_value \n",
    "    FROM trial_params\n",
    "    WHERE trial_id = (\n",
    "      SELECT trial_id\n",
    "      FROM trial_values\n",
    "      ORDER BY value DESC\n",
    "      LIMIT 1\n",
    "    );\n",
    "  ''')\n",
    "  best_hyperparams_list = cursor.fetchall()\n",
    "  best_hyperparams_dict = {}\n",
    "\n",
    "  for k, v in best_hyperparams_list:\n",
    "    if k not in ['batch_size', 'focal_alpha', 'focal_gamma', 'lr', 'optimizer', 'weight_decay']:\n",
    "      if k in ['use_text_proj', 'use_attention']:\n",
    "        best_hyperparams_dict[k] = True if v==0.0 else False\n",
    "      elif k in ['num_layers', 'bilstm_num_layers']:\n",
    "        best_hyperparams_dict[k] = int(v)\n",
    "      else:\n",
    "        best_hyperparams_dict[k] = v\n",
    "\n",
    "  cursor.execute('''\n",
    "    SELECT value\n",
    "    FROM trial_values\n",
    "    ORDER BY value DESC\n",
    "    LIMIT 1\n",
    "  ''')\n",
    "  best_f1 = cursor.fetchone()[0]\n",
    "  \n",
    "  return best_hyperparams_dict, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628781ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'checkpoints_optuna'\n",
    "model_dir_ = 'multimodal_topic_bilstm_proxy_v2'\n",
    "save_dir = 'graph_visualization'\n",
    "save_dir_ = 'multimodal_topic_bilstm_proxy_v2_id_405_ipynb'\n",
    "mode = 'multimodal_topic_bilstm_proxy'\n",
    "version = 2\n",
    "\n",
    "best_model_path = os.path.join(path_config.ROOT_DIR, model_dir, model_dir_, 'best_model.pth')\n",
    "db_path = os.path.join(path_config.ROOT_DIR, model_dir, model_dir_, 'logs', 'optuna_study.db')\n",
    "assert os.path.exists(best_model_path) and os.path.exists(db_path), logger.error(\"Model path is wrong. Try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abc8c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m13:25:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mProcessing data (Mode: multimodal_topic_bilstm_proxy)\u001b[0m\n",
      "\u001b[32m13:25:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mDoing with multimodal mode\u001b[0m\n",
      "\u001b[32m13:25:39\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[33m\u001b[1mFiltered out 2 sessions from blacklist\u001b[0m\n",
      "\u001b[32m13:25:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mGetting your model\u001b[0m\n",
      "\u001b[32m13:25:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "\u001b[32m13:25:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mSwitching CSV into Graphs\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataframe -> Graph: 100%|██████████| 45/45 [01:04<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Processing data (Mode: {mode})\")\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(path_config.DATA_DIR, 'full_test_split.csv'))\n",
    "test_id = test_df.Participant_ID.tolist()\n",
    "test_label = test_df.PHQ_Binary.tolist()\n",
    "\n",
    "if \"multimodal\" in mode:\n",
    "  logger.info(f\"Doing with multimodal mode\")\n",
    "  test_graphs, dim_list = MAKE_GRAPH[mode](\n",
    "    ids = test_id,\n",
    "    labels = test_label,                   # Temporary Label\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    use_summary_node = True,\n",
    "    t_t_connect = False,\n",
    "    v_a_connect = False\n",
    "  )\n",
    "\n",
    "  t_dim = dim_list[0]\n",
    "  v_dim = dim_list[1]\n",
    "  a_dim = dim_list[2]\n",
    "\n",
    "else:\n",
    "  logger.info(f\"Doing with non-multimodal mode\")\n",
    "  graphs, dim_list, extras = MAKE_GRAPH[mode](\n",
    "    ids = [id],\n",
    "    labels = 1,                   # Temporary Label\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    use_summary_node = True,\n",
    "    t_t_connect = False,\n",
    "    explanation = True\n",
    "  )\n",
    "\n",
    "  t_dim = dim_list[0]\n",
    "  if 'bimodal' in mode:\n",
    "    v_dim = dim_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c22d22b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mBest Params\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  - a_dropout: 0.39294858998728843\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  - bilstm_num_layers: 2\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  - g_dropout: 0.24654580705928375\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  - num_layers: 3\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  - t_dropout: 0.25237807640094945\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  - use_attention: True\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  - use_text_proj: False\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  - v_dropout: 0.3430548105111857\u001b[0m\n",
      "\u001b[32m13:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m=> F1-score: 0.7586206896551724\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams_dict, best_f1 = fetch_from_db(db_path)\n",
    "\n",
    "logger.info(f\"Best Params\")\n",
    "for k, v in best_hyperparams_dict.items():\n",
    "  logger.info(f\"  - {k}: {v}\")\n",
    "logger.info(f\"=> F1-score: {best_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d779e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m13:26:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m==============================\u001b[0m\n",
      "\u001b[32m13:26:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mLoading your model (Device: cuda)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"==============================\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Loading your model (Device: {device})\")\n",
    "\n",
    "assert version in [1,2], logger.error(\"Version should be int type 1 or 2\")\n",
    "\n",
    "if version == 2:\n",
    "  model_dict = V2_MODEL\n",
    "\n",
    "dropout_dict = {\n",
    "  'text_dropout':best_hyperparams_dict.get('t_dropout', 0.0),\n",
    "  'graph_dropout':best_hyperparams_dict.get('g_dropout', 0.0),\n",
    "  'vision_dropout':best_hyperparams_dict.get('v_dropout', 0.0),\n",
    "  'audio_dropout':best_hyperparams_dict.get('a_dropout', 0.0)\n",
    "}\n",
    "\n",
    "\n",
    "model = model_dict[mode](\n",
    "  text_dim=t_dim,\n",
    "  vision_dim=v_dim,\n",
    "  audio_dim=a_dim,\n",
    "  hidden_channels=256 if best_hyperparams_dict['use_text_proj'] else t_dim,\n",
    "  num_layers=best_hyperparams_dict['num_layers'],\n",
    "  bilstm_num_layers=best_hyperparams_dict['bilstm_num_layers'],\n",
    "  num_classes=2,\n",
    "  dropout_dict=dropout_dict,\n",
    "  heads=8,\n",
    "  use_attention=best_hyperparams_dict['use_attention'],\n",
    "  use_summary_node=True,\n",
    "  use_text_proj=best_hyperparams_dict['use_text_proj']\n",
    ").to(device)\n",
    "\n",
    "best_model_state_dict = torch.load(best_model_path)\n",
    "model.load_state_dict(best_model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e2f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|█████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  4.65it/s, Acc=0.8444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m13:30:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mValidation_F1_Score: 0.7586206896551724\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_graphs, batch_size=8, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "val_acc, val_f1 = validation_gat(\n",
    "  val_loader=test_loader,\n",
    "  model=model,\n",
    "  device=device,\n",
    "  num_classes=2\n",
    ")\n",
    "logger.info(f\"Validation_F1_Score: {val_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

training:
  lr: 0.00003
  weight-decay: 0.00042
  bs: 4
  scheduler: 'reducelr'
  warmup_epoch: 5
  focal_alpha: 0.7814
  focal_gamma: 2
  gamma: 0.5
  step-size: 50
  embed_model: 'sentence-transformers/all-MiniLM-L6-v2'

model:
  h_dim: 256
  head: 8
  num_layers: 3
  bilstm_num_layers: 2
  t_dropout: 0.2524
  g_dropout: 0.2465
  v_dropout: 0.3431
  a_dropout: 0.3929
  use_attention: True
  use_summary_node: True
  use_text_proj: False